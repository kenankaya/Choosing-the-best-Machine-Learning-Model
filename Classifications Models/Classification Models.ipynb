{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c55a86c3-ed58-4a23-803c-8591cce9ee6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1-)Logistic Regression Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34a966f-9259-4896-9ea6-e70597793176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from IPython.display import display\n",
    "\n",
    "def Logistic_Regression_Classification_Model(independent_variables,target_variable):\n",
    "    print(\"************************************* Logistic Regression Classification Model ***********************************************\")\n",
    "    \n",
    "    \n",
    "    def optimum_parameters_of_model(independent_variables, target_variable):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "        loj_reg_model = LogisticRegression()\n",
    "        loj_reg_params={\"solver\" : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                        \"C\": np.arange(1,25)}\n",
    "        loj_reg_cv_model=GridSearchCV(loj_reg_model ,\n",
    "                                      loj_reg_params, \n",
    "                                      cv = 10, \n",
    "                                      n_jobs = -1)\n",
    "        loj_reg_cv_model.fit(X_train, y_train)\n",
    "        optimum_parameters=loj_reg_cv_model.best_params_\n",
    "        print(\"Optimum Parameters of the model are {}\".format(optimum_parameters))\n",
    "        return optimum_parameters\n",
    "    \n",
    "    a=optimum_parameters_of_model(independent_variables, target_variable)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "    global loj_reg_model\n",
    "    loj_reg_model = LogisticRegression(C=a['C'], solver=a['solver']).fit(X_train, y_train)\n",
    "    predictions= loj_reg_model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    def AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions):\n",
    "\n",
    "        if y_test.nunique()>2:\n",
    "            print(classification_report(y_test,predictions))\n",
    "\n",
    "            def df_accuracy_score_multiple(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                             columns=[\"Score\"],\n",
    "                             index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            a=df_accuracy_score_multiple(y_test,predictions)\n",
    "            b=df_confusion_matrix(y_test,predictions)\n",
    "            return display(a),display(b)\n",
    "        else:\n",
    "            print(classification_report(y_test,predictions))\n",
    "            def df_accuracy_score_binary(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                              columns=[\"Score\"],\n",
    "                              index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            c=df_accuracy_score_binary(y_test,predictions)\n",
    "            d=df_confusion_matrix(y_test,predictions)\n",
    "\n",
    "            return  display(c),display(d)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "  \n",
    "    b=AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions)\n",
    "    \n",
    "    \n",
    "    return a,display(b)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52003c89-93c4-48b2-8ca1-8cec57e56204",
   "metadata": {},
   "source": [
    "# 2-)Naive Bayes Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d86503-fdcb-4c2c-babb-b5d25e7632f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from IPython.display import display\n",
    "\n",
    "def Naive_Bayes_Classification_Model(independent_variables,target_variable):\n",
    "    print(\"************************************* Naive Bayes Classification Model ***********************************************\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "    global nb_model\n",
    "    nb_model = GaussianNB().fit(X_train, y_train)\n",
    "    predictions= nb_model.predict(X_test)\n",
    "    \n",
    "    def AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions):\n",
    "\n",
    "        if y_test.nunique()>2:\n",
    "            print(classification_report(y_test,predictions))\n",
    "\n",
    "            def df_accuracy_score_multiple(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                             columns=[\"Score\"],\n",
    "                             index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            a=df_accuracy_score_multiple(y_test,predictions)\n",
    "            b=df_confusion_matrix(y_test,predictions)\n",
    "            return display(a),display(b)\n",
    "        else:\n",
    "            print(classification_report(y_test,predictions))\n",
    "            def df_accuracy_score_binary(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                              columns=[\"Score\"],\n",
    "                              index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            c=df_accuracy_score_binary(y_test,predictions)\n",
    "            d=df_confusion_matrix(y_test,predictions)\n",
    "\n",
    "            return  display(c),display(d)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "  \n",
    "    b=AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions)\n",
    "    \n",
    "    \n",
    "    return display(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452f9a5c-f66a-4b8b-a069-618f5c09c638",
   "metadata": {},
   "source": [
    "# 3-)KNN Classsificcation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5edb797-f619-4f74-a6d8-a07b46d11f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from IPython.display import display\n",
    "\n",
    "def K_Nearest_Classification_Model(independent_variables,target_variable):\n",
    "    print(\"************************************* K Nearest Classification Model ***********************************************\")\n",
    "    \n",
    "    \n",
    "    def optimum_parameters_of_model(independent_variables, target_variable):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "        X_train_scaled=StandardScaler().fit_transform(X_train)\n",
    "        X_test_scaled=StandardScaler().fit_transform(X_test)\n",
    "        \n",
    "        knn=KNeighborsClassifier()\n",
    "        knn_params = {\"n_neighbors\": np.arange(1,50),\n",
    "                     \"metric\":[ \"minkowski\",\"manhattan\",\"euclidean\"]}\n",
    "        knn_cv_model = GridSearchCV(knn, knn_params, cv=10,n_jobs=-1)\n",
    "        knn_cv_model.fit(X_train_scaled, y_train)\n",
    "        optimum_parameters=knn_cv_model.best_params_\n",
    "        print(\"Optimum Parameters of the model are {}\".format(optimum_parameters))\n",
    "        return optimum_parameters\n",
    "    \n",
    "    a=optimum_parameters_of_model(independent_variables, target_variable)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "    X_train_scaled=StandardScaler().fit_transform(X_train)\n",
    "    X_test_scaled=StandardScaler().fit_transform(X_test)\n",
    "    global knn_model \n",
    "    knn_model = KNeighborsClassifier(n_neighbors=a['n_neighbors'], metric=a['metric']).fit(X_train_scaled, y_train)\n",
    "    predictions= knn_model.predict(X_test_scaled)\n",
    "    \n",
    "    def AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions):\n",
    "\n",
    "        if y_test.nunique()>2:\n",
    "            print(classification_report(y_test,predictions))\n",
    "\n",
    "            def df_accuracy_score_multiple(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                             columns=[\"Score\"],\n",
    "                             index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            a=df_accuracy_score_multiple(y_test,predictions)\n",
    "            b=df_confusion_matrix(y_test,predictions)\n",
    "            return display(a),display(b)\n",
    "        else:\n",
    "            print(classification_report(y_test,predictions))\n",
    "            def df_accuracy_score_binary(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                              columns=[\"Score\"],\n",
    "                              index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            c=df_accuracy_score_binary(y_test,predictions)\n",
    "            d=df_confusion_matrix(y_test,predictions)\n",
    "\n",
    "            return  display(c),display(d)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "  \n",
    "    b=AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions)\n",
    "    \n",
    "    \n",
    "    return a,display(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ce2c58-5ef1-471a-8919-a9742db3f79a",
   "metadata": {},
   "source": [
    "# 4-) Support Vector Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b845b9-5a3a-4c70-ac83-97232a7df624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from IPython.display import display\n",
    "\n",
    "def Support_Vector_Classification_Model(independent_variables,target_variable):\n",
    "    print(\"************************************* Support Vector Classification Model ***********************************************\")\n",
    "    \n",
    "    \n",
    "    def optimum_parameters_of_model(independent_variables, target_variable):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "        svc = SVC()\n",
    "        \n",
    "        svc_params = {\"C\": np.arange(1,25,0.1),\n",
    "                     \"gamma\": [0.0001, 0.001, 0.1, 1, 5, 10 ,50 ,100]}\n",
    "\n",
    "        svc_cv_model = GridSearchCV(svc,svc_params, \n",
    "                                    cv = 10, \n",
    "                                    n_jobs = -1)\n",
    "        svc_cv_model.fit(X_train, y_train)\n",
    "        \n",
    "        optimum_parameters= svc_cv_model.best_params_\n",
    "        print(\"Optimum Parameters of the model are {}\".format(optimum_parameters))\n",
    "        return optimum_parameters\n",
    "    \n",
    "    a=optimum_parameters_of_model(independent_variables, target_variable)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "    global svc_model\n",
    "    svc_model = SVC(C=a['C'],gamma=a['gamma']).fit(X_train, y_train)\n",
    "    predictions= svc_model.predict(X_test)\n",
    "    \n",
    "    def AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions):\n",
    "\n",
    "        if y_test.nunique()>2:\n",
    "            print(classification_report(y_test,predictions))\n",
    "\n",
    "            def df_accuracy_score_multiple(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                             columns=[\"Score\"],\n",
    "                             index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            a=df_accuracy_score_multiple(y_test,predictions)\n",
    "            b=df_confusion_matrix(y_test,predictions)\n",
    "            return display(a),display(b)\n",
    "        else:\n",
    "            print(classification_report(y_test,predictions))\n",
    "            def df_accuracy_score_binary(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                              columns=[\"Score\"],\n",
    "                              index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            c=df_accuracy_score_binary(y_test,predictions)\n",
    "            d=df_confusion_matrix(y_test,predictions)\n",
    "\n",
    "            return  display(c),display(d)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "  \n",
    "    b=AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions)\n",
    "    \n",
    "    \n",
    "    return a,display(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866eb2a1-1a52-4c7b-93e2-5f51cba5217a",
   "metadata": {},
   "source": [
    "# 5-)Multiple Layers Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067ab2cb-ef8b-4aba-bbb6-0300a0f7eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from IPython.display import display\n",
    "\n",
    "def Multiple_Layers_Classification_Model(independent_variables,target_variable):\n",
    "    print(\"************************************* Multiple Layers Classification Model ***********************************************\")\n",
    "    \n",
    "    \n",
    "    def optimum_parameters_of_model(independent_variables, target_variable):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "        X_train_scaled=StandardScaler().fit_transform(X_train)\n",
    "        X_test_scaled=StandardScaler().fit_transform(X_test)\n",
    "        mlpc = MLPClassifier()\n",
    "        mlpc_params = {\"alpha\": [1, 0.1, 0.01, 0.02, 0.005, 0.0001,0.00001],\n",
    "                       \"hidden_layer_sizes\": [(100,100,100),(100,100),(70,70,60),(150,150)],\n",
    "                       \"solver\" : [\"lbfgs\",\"adam\",\"sgd\"],\n",
    "                       \"activation\": [\"relu\",\"logistic\"]}\n",
    "        mlpc_cv_model = GridSearchCV(mlpc, mlpc_params, cv = 10, n_jobs = -1)\n",
    "        mlpc_cv_model.fit(X_train_scaled, y_train)\n",
    "        optimum_parameters=mlpc_cv_model.best_params_\n",
    "        print(\"Optimum Parameters of the model are {}\".format(optimum_parameters))\n",
    "        return optimum_parameters\n",
    "    \n",
    "    a=optimum_parameters_of_model(independent_variables, target_variable)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "    X_train_scaled=StandardScaler().fit_transform(X_train)\n",
    "    X_test_scaled=StandardScaler().fit_transform(X_test)\n",
    "    global mlpc_model\n",
    "    mlpc_model = MLPClassifier(alpha=a['alpha'], hidden_layer_sizes=a['hidden_layer_sizes'],solver=a['solver'],activation=a['activation']).fit(X_train_scaled, y_train)\n",
    "    predictions= mlpc_model.predict(X_test_scaled)\n",
    "    \n",
    "    def AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions):\n",
    "\n",
    "        if y_test.nunique()>2:\n",
    "            print(classification_report(y_test,predictions))\n",
    "\n",
    "            def df_accuracy_score_multiple(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                             columns=[\"Score\"],\n",
    "                             index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            a=df_accuracy_score_multiple(y_test,predictions)\n",
    "            b=df_confusion_matrix(y_test,predictions)\n",
    "            return display(a),display(b)\n",
    "        else:\n",
    "            print(classification_report(y_test,predictions))\n",
    "            def df_accuracy_score_binary(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                              columns=[\"Score\"],\n",
    "                              index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            c=df_accuracy_score_binary(y_test,predictions)\n",
    "            d=df_confusion_matrix(y_test,predictions)\n",
    "\n",
    "            return  display(c),display(d)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "  \n",
    "    b=AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions)\n",
    "    \n",
    "    \n",
    "    return a,display(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be8323-954b-4564-88db-067d02072094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f84cfd8-36f2-4306-af02-12ae9636a18f",
   "metadata": {},
   "source": [
    "# 6-)Cart Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492f654b-5f2a-469e-8546-15fbacdd9ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from IPython.display import display\n",
    "\n",
    "def CART_Classification_Model(independent_variables,target_variable):\n",
    "    print(\"************************************* CART Classification Model ***********************************************\")\n",
    "    \n",
    "    \n",
    "    def optimum_parameters_of_model(independent_variables, target_variable):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "        cart = DecisionTreeClassifier()\n",
    "        cart_grid = {\"max_depth\": range(1,30),\n",
    "                     \"min_samples_split\" : list(range(2,70)),\n",
    "                     \"criterion\":['gini','entropy']}      \n",
    "        cart_cv_model = GridSearchCV(cart, cart_grid, cv = 10, n_jobs = -1)\n",
    "        cart_cv_model = cart_cv_model.fit(X_train, y_train)\n",
    "        optimum_parameters= cart_cv_model.best_params_\n",
    "        print(\"Optimum Parameters of the model are {}\".format(optimum_parameters))\n",
    "        return optimum_parameters\n",
    "    \n",
    "    a=optimum_parameters_of_model(independent_variables, target_variable)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "    global cart_model\n",
    "    cart_model = DecisionTreeClassifier(max_depth=a['max_depth'],min_samples_split=a['min_samples_split'],criterion=a['criterion']).fit(X_train, y_train)\n",
    "    predictions= cart_model.predict(X_test)\n",
    "    \n",
    "    def AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions):\n",
    "\n",
    "        if y_test.nunique()>2:\n",
    "            print(classification_report(y_test,predictions))\n",
    "\n",
    "            def df_accuracy_score_multiple(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                             columns=[\"Score\"],\n",
    "                             index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            a=df_accuracy_score_multiple(y_test,predictions)\n",
    "            b=df_confusion_matrix(y_test,predictions)\n",
    "            return display(a),display(b)\n",
    "        else:\n",
    "            print(classification_report(y_test,predictions))\n",
    "            def df_accuracy_score_binary(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                              columns=[\"Score\"],\n",
    "                              index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            c=df_accuracy_score_binary(y_test,predictions)\n",
    "            d=df_confusion_matrix(y_test,predictions)\n",
    "\n",
    "            return  display(c),display(d)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "  \n",
    "    b=AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions)\n",
    "    \n",
    "    \n",
    "    return a,display(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a509137e-a822-4c59-bf3c-0fda1ad0ef80",
   "metadata": {},
   "source": [
    "# 7-)Random Forest Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c14bf29-7941-47f7-9eb5-19d80cec956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from IPython.display import display\n",
    "\n",
    "def Random_Forest_Classification_Model(independent_variables,target_variable):\n",
    "    print(\"************************************* Random Forest Classification Model ***********************************************\")\n",
    "    \n",
    "    \n",
    "    def optimum_parameters_of_model(independent_variables, target_variable):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "        rf_model = RandomForestClassifier()\n",
    "        rf_params = {\"max_depth\": [3,8,10,20],\n",
    "                     \"max_features\": [2,5,8,13],\n",
    "                     \"n_estimators\": [100,200,500],\n",
    "                     \"min_samples_split\": [2,5,10]}\n",
    "        rf_cv_model = GridSearchCV(rf_model, rf_params, cv = 10,n_jobs = -1) \n",
    "        rf_cv_model = rf_cv_model.fit(X_train, y_train)\n",
    "        optimum_parameters= rf_cv_model.best_params_\n",
    "        print(\"Optimum Parameters of the model are {}\".format(optimum_parameters))\n",
    "        return optimum_parameters\n",
    "    \n",
    "    a=optimum_parameters_of_model(independent_variables, target_variable)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "    global rf_model\n",
    "    rf_model = RandomForestClassifier(max_depth=a['max_depth'],\n",
    "                                      min_samples_split=a['min_samples_split'],\n",
    "                                      max_features=a['max_features'],\n",
    "                                      n_estimators=a['n_estimators']).fit(X_train, y_train)\n",
    "    predictions= rf_model.predict(X_test)\n",
    "    \n",
    "    def AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions):\n",
    "\n",
    "        if y_test.nunique()>2:\n",
    "            print(classification_report(y_test,predictions))\n",
    "\n",
    "            def df_accuracy_score_multiple(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                             columns=[\"Score\"],\n",
    "                             index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            a=df_accuracy_score_multiple(y_test,predictions)\n",
    "            b=df_confusion_matrix(y_test,predictions)\n",
    "            return display(a),display(b)\n",
    "        else:\n",
    "            print(classification_report(y_test,predictions))\n",
    "            def df_accuracy_score_binary(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                              columns=[\"Score\"],\n",
    "                              index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            c=df_accuracy_score_binary(y_test,predictions)\n",
    "            d=df_confusion_matrix(y_test,predictions)\n",
    "\n",
    "            return  display(c),display(d)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "  \n",
    "    b=AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions)\n",
    "    \n",
    "    \n",
    "    return a,display(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4575d99e-d688-4634-9313-7b985b2196c7",
   "metadata": {},
   "source": [
    "# 8-)Gradient Boosting Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74562364-4dc0-4827-90e9-f0c31576068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from IPython.display import display\n",
    "\n",
    "def Gradient_Boosting_Classification_Model(independent_variables,target_variable):\n",
    "    print(\"************************************* Gradient Boosting Classification Model ***********************************************\")\n",
    "    \n",
    "    \n",
    "    def optimum_parameters_of_model(independent_variables, target_variable):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "        gbm = GradientBoostingClassifier()\n",
    "        gbm_params = {\"learning_rate\" : [0.001, 0.01, 0.1, 0.05],\n",
    "                      \"n_estimators\": [100,200,500],\n",
    "                      \"max_depth\": [2,5,8,13],\n",
    "                      \"min_samples_split\": [2,5,10]}\n",
    "        gbm_cv = GridSearchCV(gbm, gbm_params, cv = 10, n_jobs = -1)\n",
    "        gbm_cv_model = gbm_cv.fit(X_train, y_train)\n",
    "        optimum_parameters= gbm_cv_model.best_params_\n",
    "        print(\"Optimum Parameters of the model are {}\".format(optimum_parameters))\n",
    "        return optimum_parameters\n",
    "    \n",
    "    a=optimum_parameters_of_model(independent_variables, target_variable)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "    global gbm_model\n",
    "    gbm_model = GradientBoostingClassifier(max_depth=a['max_depth'],\n",
    "                                           min_samples_split=a['min_samples_split'],\n",
    "                                           learning_rate=a['learning_rate'],\n",
    "                                           n_estimators=a['n_estimators']).fit(X_train, y_train)\n",
    "    predictions= gbm_model.predict(X_test)\n",
    "    \n",
    "    def AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions):\n",
    "\n",
    "        if y_test.nunique()>2:\n",
    "            print(classification_report(y_test,predictions))\n",
    "\n",
    "            def df_accuracy_score_multiple(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                             columns=[\"Score\"],\n",
    "                             index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            a=df_accuracy_score_multiple(y_test,predictions)\n",
    "            b=df_confusion_matrix(y_test,predictions)\n",
    "            return display(a),display(b)\n",
    "        else:\n",
    "            print(classification_report(y_test,predictions))\n",
    "            def df_accuracy_score_binary(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                              columns=[\"Score\"],\n",
    "                              index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            c=df_accuracy_score_binary(y_test,predictions)\n",
    "            d=df_confusion_matrix(y_test,predictions)\n",
    "\n",
    "            return  display(c),display(d)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "  \n",
    "    b=AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions)\n",
    "    \n",
    "    \n",
    "    return a,display(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9f7d62-dd94-4df6-9baa-b9d1fa212dfd",
   "metadata": {},
   "source": [
    "# 9-)Extreme Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2287b431-ab0a-49ae-8b9d-d0f730de9b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from IPython.display import display\n",
    "\n",
    "def XGBoost_Classification_Model(independent_variables,target_variable):\n",
    "    print(\"************************************* Extreme Gradient Boosting Classification Model ***********************************************\")\n",
    "    \n",
    "    \n",
    "    def optimum_parameters_of_model(independent_variables, target_variable):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "        xgb = XGBClassifier()\n",
    "        xgb_params = {'n_estimators': [100, 500, 1000],\n",
    "                      'subsample': [0.6, 0.8, 1.0],\n",
    "                      'max_depth': [3, 4, 5,6],\n",
    "                      'learning_rate': [0.001,0.1,0.01,0.02,0.05],\n",
    "                       }\n",
    "        xgb_cv = GridSearchCV(xgb, xgb_params, cv = 10, n_jobs = -1)\n",
    "        xgb_cv_model=xgb_cv.fit(X_train, y_train)\n",
    "        optimum_parameters= xgb_cv_model.best_params_\n",
    "        print(\"Optimum Parameters of the model are {}\".format(optimum_parameters))\n",
    "        return optimum_parameters\n",
    "    \n",
    "    a=optimum_parameters_of_model(independent_variables, target_variable)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "    global xgb_model\n",
    "    xgb_model = XGBClassifier(max_depth=a['max_depth'],\n",
    "                              learning_rate=a['learning_rate'],\n",
    "                              n_estimators=a['n_estimators'],\n",
    "                              subsample=a['subsample']).fit(X_train, y_train)\n",
    "    predictions= xgb_model.predict(X_test)\n",
    "    \n",
    "    def AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions):\n",
    "\n",
    "        if y_test.nunique()>2:\n",
    "            print(classification_report(y_test,predictions))\n",
    "\n",
    "            def df_accuracy_score_multiple(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                             columns=[\"Score\"],\n",
    "                             index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            a=df_accuracy_score_multiple(y_test,predictions)\n",
    "            b=df_confusion_matrix(y_test,predictions)\n",
    "            return display(a),display(b)\n",
    "        else:\n",
    "            print(classification_report(y_test,predictions))\n",
    "            def df_accuracy_score_binary(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                              columns=[\"Score\"],\n",
    "                              index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            c=df_accuracy_score_binary(y_test,predictions)\n",
    "            d=df_confusion_matrix(y_test,predictions)\n",
    "\n",
    "            return  display(c),display(d)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "  \n",
    "    b=AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions)\n",
    "    \n",
    "    \n",
    "    return a,display(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ce798c-da22-4e25-98de-71421070f832",
   "metadata": {},
   "source": [
    "# 10-)LightGBM Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eaf963-3df0-4dcd-80eb-ffd6a305d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from IPython.display import display\n",
    "\n",
    "def LightGBM_Classification_Model(independent_variables,target_variable):\n",
    "    print(\"************************************* LightGBM Classification Model ***********************************************\")\n",
    "    \n",
    "    \n",
    "    def optimum_parameters_of_model(independent_variables, target_variable):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "        lgbm = LGBMClassifier()\n",
    "        lgbm_params = {'n_estimators': [100, 500, 1000],\n",
    "                       'subsample': [0.6, 0.8, 1.0],\n",
    "                       'max_depth': [3, 4, 5,6],\n",
    "                       'learning_rate': [0.001,0.1,0.01,0.02,0.05],\n",
    "                       'min_child_samples': [5,10,20]}\n",
    "        lgbm_cv = GridSearchCV(lgbm, lgbm_params, cv = 10, n_jobs = -1)\n",
    "        lgbm_cv_model=lgbm_cv.fit(X_train, y_train)\n",
    "        optimum_parameters= lgbm_cv_model.best_params_\n",
    "        print(\"Optimum Parameters of the model are {}\".format(optimum_parameters))\n",
    "        return optimum_parameters\n",
    "    \n",
    "    a=optimum_parameters_of_model(independent_variables, target_variable)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "    global lgbm_model\n",
    "    lgbm_model = LGBMClassifier(max_depth=a['max_depth'],\n",
    "                                min_child_samples=a['min_child_samples'],\n",
    "                                learning_rate=a['learning_rate'],\n",
    "                                n_estimators=a['n_estimators'],\n",
    "                                subsample=a['subsample']).fit(X_train, y_train)\n",
    "    predictions= lgbm_model.predict(X_test)\n",
    "    \n",
    "    def AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions):\n",
    "\n",
    "        if y_test.nunique()>2:\n",
    "            print(classification_report(y_test,predictions))\n",
    "\n",
    "            def df_accuracy_score_multiple(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                             columns=[\"Score\"],\n",
    "                             index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            a=df_accuracy_score_multiple(y_test,predictions)\n",
    "            b=df_confusion_matrix(y_test,predictions)\n",
    "            return display(a),display(b)\n",
    "        else:\n",
    "            print(classification_report(y_test,predictions))\n",
    "            def df_accuracy_score_binary(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                              columns=[\"Score\"],\n",
    "                              index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            c=df_accuracy_score_binary(y_test,predictions)\n",
    "            d=df_confusion_matrix(y_test,predictions)\n",
    "\n",
    "            return  display(c),display(d)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "  \n",
    "    b=AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions)\n",
    "    \n",
    "    \n",
    "    return a,display(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cda8db2-01e8-4d8e-a0e0-3fe5a0fd8575",
   "metadata": {},
   "source": [
    "# 11-)CatBoost Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5f2e3e-bac8-4fa4-a716-06404f99c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from IPython.display import display\n",
    "\n",
    "def CatBoost_Classification_Model(independent_variables,target_variable):\n",
    "    print(\"************************************* CatBoost Classification Model ***********************************************\")\n",
    "    \n",
    "    \n",
    "    def optimum_parameters_of_model(independent_variables, target_variable):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "        catb = CatBoostClassifier()\n",
    "        catb_params = {'iterations': [100,200,500],\n",
    "                       'learning_rate': [0.001,0.01,0.05, 0.1],\n",
    "                        'depth': [3,5,8,13]}\n",
    "        catb_cv = GridSearchCV(catb, catb_params, cv=5, n_jobs = -1)\n",
    "        catb_cv_model=catb_cv.fit(X_train, y_train)\n",
    "        optimum_parameters= catb_cv_model.best_params_\n",
    "        print(\"Optimum Parameters of the model are {}\".format(optimum_parameters))\n",
    "        return optimum_parameters\n",
    "    \n",
    "    a=optimum_parameters_of_model(independent_variables, target_variable)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "    global catb_model\n",
    "    catb_model = CatBoostClassifier(depth=a['depth'],\n",
    "                                    iterations=a['iterations'],\n",
    "                                    learning_rate=a['learning_rate']).fit(X_train, y_train)\n",
    "    predictions= catb_model.predict(X_test)\n",
    "    \n",
    "    def AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions):\n",
    "\n",
    "        if y_test.nunique()>2:\n",
    "            print(classification_report(y_test,predictions))\n",
    "\n",
    "            def df_accuracy_score_multiple(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                             columns=[\"Score\"],\n",
    "                             index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            a=df_accuracy_score_multiple(y_test,predictions)\n",
    "            b=df_confusion_matrix(y_test,predictions)\n",
    "            return display(a),display(b)\n",
    "        else:\n",
    "            print(classification_report(y_test,predictions))\n",
    "            def df_accuracy_score_binary(y_test,predictions):\n",
    "                y=pd.DataFrame(round(accuracy_score(y_test,predictions),ndigits=3),\n",
    "                              columns=[\"Score\"],\n",
    "                              index=[\"Accuracy\"])\n",
    "                return y\n",
    "\n",
    "            def df_confusion_matrix(y_test,predictions):\n",
    "                ind_m=pd.MultiIndex.from_product([[\"Actual\"],sorted(list(set(y_test.values)))])\n",
    "                col_m=pd.MultiIndex.from_product([[\"Predicted\"],sorted(list(set(y_test.values)))])\n",
    "                x=pd.DataFrame(confusion_matrix(y_test,predictions),\n",
    "                                                columns=col_m,\n",
    "                                                index=ind_m)\n",
    "                return x\n",
    "\n",
    "            c=df_accuracy_score_binary(y_test,predictions)\n",
    "            d=df_confusion_matrix(y_test,predictions)\n",
    "\n",
    "            return  display(c),display(d)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "  \n",
    "    b=AccuracyScore_ConfusionMatrix_ClassificationReport(y_test,predictions)\n",
    "    \n",
    "    \n",
    "    return a,display(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027530ec-bf76-4683-933b-1383880b20ee",
   "metadata": {},
   "source": [
    "# 12-)Receiver_Operating_Characteristic_ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b55a23c-66c4-4507-a093-ef578c16e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Receiver_Operating_Characteristic_ROC(independent_variables,target_variable):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(independent_variables, target_variable,  test_size = 0.25, random_state = 101)\n",
    "    if y_test.nunique()!=2:\n",
    "        print(\"This function is convenient and valid  for only binary classificition problem.\\nTarget Variable has more than 2 classes.\")\n",
    "    else:\n",
    "        model_list=[loj_reg_model,nb_model,knn_model,mlpc_model,cart_model,rf_model,gbm_model,xgb_model,lgbm_model]\n",
    "        model_name_list=[\"Logistic Regression\",\n",
    "                         \"Naive Bayes\",\n",
    "                         \"K-nearest Neighbors\",\n",
    "                         \"Multiple Layer Perception\",\n",
    "                         \"Classification and Regression Trees\",\n",
    "                         \"Random Forest\",\n",
    "                         \"Gradient Boosting\",\n",
    "                         \"Extreme Gradient Boosting\"\n",
    "                         \"LightGBM\"]\n",
    "        color_list=[\"indigo\",\"maroon\",\"lime\",\"navy\",\"magenta\",\"darkcyan\",\"peru\",\"green\",\"black\"]\n",
    "        roc_auc_list=[]\n",
    "        fpr_list=[]\n",
    "        tpr_list=[]\n",
    "        for model in model_list:\n",
    "            fpr, tpr, thresholds = roc_curve(target_variable, model.predict_proba(independent_variables)[:,1])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            roc_auc_list.append(roc_auc)\n",
    "            fpr_list.append(fpr)\n",
    "            tpr_list.append(tpr)\n",
    "            \n",
    "        plt.figure(figsize=(15,10))    \n",
    "        for model,roc_auc_,fpr_,tpr_ ,color in zip(model_name_list,roc_auc_list,fpr_list,tpr_list,color_list):\n",
    "            plt.plot(fpr_, tpr_, color, label= model + '(AUC = {:.2f})'.format(roc_auc_))\n",
    "        \n",
    "     \n",
    "        plt.legend(loc = 'lower right')\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.show()   \n",
    "            \n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47dd360-fe10-438a-823d-ca497ec6e7ac",
   "metadata": {},
   "source": [
    "# Codes are Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948f25ad-caae-4e59-b44f-2e89d215dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_Regression_Classification_Model(independent_variables,target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c78eed-a2b2-4140-9c7f-b55e6a0775c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Naive_Bayes_Classification_Model(independent_variables,target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fbe02e-db9c-4d02-a012-81e5fdb12e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_Nearest_Classification_Model(independent_variables,target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38fed08-3f6f-4c1a-b713-b9a7fd21860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Support_Vector_Classification_Model(independent_variables,target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f323667b-fa03-47fe-b09c-0ed196f31ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Multiple_Layers_Classification_Model(independent_variables,target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5905fd-4db7-4006-98d9-c1869ee592f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CART_Classification_Model(independent_variables,target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bb7547-af40-48ec-822a-c09ab7441b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random_Forest_Classification_Model(independent_variables,target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46145c3-b94a-4b58-908d-cf90c252df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gradient_Boosting_Classification_Model(independent_variables,target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46244cb0-f7b8-4a75-bc9a-0aa7e66417e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost_Classification_Model(independent_variables,target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e5263f-e8f5-4721-a9f4-3bf442046d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "LightGBM_Classification_Model(independent_variables,target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e24bb0-d157-404c-85b0-f08d9150a532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CatBoost_Classification_Model(independent_variables,target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f65bec-ff3b-436a-875b-546e0f691c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Receiver_Operating_Characteristic_ROC(independent_variables,target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc55ef-64fd-495f-b3f3-c4de6e550ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
